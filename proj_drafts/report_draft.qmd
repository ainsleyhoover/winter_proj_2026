---
title: "Fact versus Fiction: Verifying Predictor Conventions for New York"
author: 
  - Matthew Cohen^[American University]
  - Ainsley Hoover^[American University]
  - Samari Ijezie^[American University]
format: 
  pdf:
    number-sections: true
    toc: false
    geometry: 
      - top=3cm
date: 2025-06-25
date-format: iso
documentclass: article
editor: source
abstract: "This study examines how well age, income, and gender predict party identification among registered voters in New York State. Using a 1% sample of the 2021 New York voter file from L2 (N ≈ 84,000), we estimate the predictive power of these demographic variables using bivariate and generalized linear models. We find that income and age provide modest predictive value for distinguishing between Democratic and Republican affiliation, while gender contributes comparatively little explanatory power. Overall, demographic variables alone perform weakly at the individual level, highlighting the limits of commonly cited partisan generalizations. These findings suggest that while demographic trends exist in aggregate, party identification in New York has apparent correlations with income, age, and gender."
bibliography: main.bib
---

```{r}
#| label: setup
#| echo: false
#| message: false

# This chunk loads any packages we need.
# Because "message: false", any R messages from this chunk do not appear in our paper.

library(tidyverse)
library(ggthemes)
```

```{r}
#| echo: false
#| message: false

# This chunk might read our data.
# It might clean the data, create new variables, etc.
# Now our data are ready for our paper.

# Because echo: false, this chunk itself is not shown.


```

```{r}
#| label: readdata
#| echo: false
#| eval: false
 
# Because eval: false, this chunk is not run.

data_ny <- read_csv("kept_only_r_d_for_party_id_output.csv")
df <- tibble(data_ny)
```

# Introduction

In this section, we introduce the reader to the phenomenon we investigate. We describe the way in which our analysis contributes to an important intellectual debate, or how it answers a pressing political or social question. We introduce our research question, hypotheses, data, and results. We signpost for the reader what's coming in the rest of the paper.

We remember that our paper is not a mystery novel. We note our core results early and often.

Throughout our paper, we use active, first-person language and avoid the passive voice. For example, we write "we examine the relationship between $X$ and $Y$"; we do not write "the relationship between $X$ and $Y$ was examined." Where we do the analysis, we speak about it transparently. We use the present tense; for example, "In this paper, we argue \ldots" and "Paper XYZ demonstrates the relationship between \ldots".

# In Search of Nuance

Age, gender, and income, are commonly described as predictors for party affiliation. In introductory-level civics courses, students are taught about how the older and richer one is, the more conservative they are likely to be. As people get older, they shift away from the Republican party (Knoke and Hout, 1974). In addition, the gender gap in the United States' two party system is highly referenced. Women lean more democratic than men (Box-Steffensmeier et al., 2004; Miller, 1991). There is a plethora of research showcasing the effect of demographic information on voting (a quick search on Google Scholar of "demographic effects on voting" renders more than 1.3 million results). However, attention to voting predictors is rarely given at the state level. Our country that is hyper-fixated on presidential elections. Thus, we hoped to move away from that narrative and dissect one aspect of voters at the state-level. We wanted to verify if age, gender, and income are strong determiners for categorizing partisanship or if the raw data presents a different picture.

Selecting New York as a key state may seem odd, as the state is not a swing state and heavily favors the Democratic party. In other words, nationally, it is often predictable and not a good representation of the United States of America at large. This is precisely why we chose New York: it might be an outlier to general conventions. There may be general cohort effects to the elderly or youth specific to New York that national data misses. New York City's 2025 mayoral election elected Mamdani, an untraditional Democrat, to their office. While New York City is by no means representative of the state as a whole, it goes to show that the region acts as an anomaly to what the nation would typically elect. Thus, we wondered if New York had unique attributes, related to age, income, or gender, that allowed for its democratic-party favoritism. Age may not be the only factor at play for party identification: income and gender may hold key influence as well.

In a diverse and expansive world, it seems pertinent to take caution to generalizations. Generalizations about party identification are most accurate at the population level. It is vital to remember that the population is distinct from an individual. There is much intellectual debate about the reliability of party identification assumptions. Tomkins et al. (2025) argue that certain demographics can only prove partisanship by so much. Seo-young Kim and Zilinsky (2022) found that machine learning models trained on demographic labels from public opinion surveys predicted partisan identification correctly only 63.4% of the time. By focusing on one state, we hope to shift away from nationally-applied partisanship influences and verify their accuracy for the state of New York.

# Data and Methods {#sec-data}

For this report, we analyzed data from the 2021 New York voter files. In it were registered voters' names, registered addresses, ages, vote histories, and party affiliations, among hundreds of other variables. We obtained this data from L2, a gold-standard database for the United States' voter files. We received this data through Joshua Ferrer's access. He gave us a 1% of the raw data, which is still substantially large enough to do successful analysis with. Our sliced data still contained 125,046 voters with 1,180 variables about them. This data is very rich in content, but some variables lacked enough presence to be useful. For example, the education data is an estimate from consumer-sold data. Despite this information being wildly circulated online, half of our data's New Yorkers were lacking education attainment level data. For this reason, it did not feel as a representative metric to use. This led us to analyzing age, gender, and income as over 90% of voters had that information.

Since this data was very large, we took many steps to make it useful for our purposes in predicting partisanship. First, we chose our useful variables of voter identification, age, date of birth, partisan affiliation, ethnicity, religion, estimated income, education, gender, activity of the voter, and the county in which the voter resided. Due to concerns about the quality of data, as many of these variables are faulty at the individual level, we removed education, religion, and ethnicity. For our goal of predicting party identification, we also filtered out inactive voters as they are not likely to have strong identification with their party affiliation and no longer vote in the state of New York. This could have been due to residency, fatality, criminal status, or otherwise. We also coded gender with a binary scale, with 0 as male and 1 as female. There were 36 voters with no gender information, which we elected to filter out, as they were not a significant portion of the population. For party identification, we decided to focus only on the affiliated Republicans and Democrats for simplicity in our data. We made all of these changes through a workspace in Redivis as to not overwhelm R.

Our primary research interest is the effectiveness of three variables, gender, age, and income, in predicting party identification. We did this through linear regression. We did the linear regression using R, relying on the tidyverse package and ggthemes. We hypothesized that income would be the strongest indicator, followed by age, and then gender.

# \[Our Results Section Title Here\]

Here, we explain and interpret our results. We try to learn as much as we can about our question as possible, given the data and analysis. We present our results clearly. We interpret them for the reader with precision and circumspection. We avoid making claims that are not substantiated by our data. We are careful about causality. When we describe associations, we avoid language like "effects" and "increases"; we only describe "effects" or "impacts" when we have a causally well-identified research design.

Note that this section may be integrated into @sec-data, if joining the two improves the overall presentation.

## Predicting Distance with Speed

Our results for the `cars` data include estimating the linear model

$$\text{Distance}_i = \beta_0 + \beta_1 (\text{Speed}_i) + \epsilon_i.$$ Perhaps we start by plotting the data, as in @fig-cars.

```{r}
#| label:  fig-cars
#| echo: false
#| fig-cap: Distance on Speed

ggplot(cars, aes(speed, dist)) +
  geom_point()
```

The data may be roughly linear, though there may be some non-linearity we should incorporate.

```{r linearmodel}
#| echo: false

# Estimate a linear model:
lm_out <- lm(dist ~ speed, data = cars)
# Extract the coefficient on speed:
cars_speed_coef <- coef(lm_out)["speed"]
```

Below we show the model estimates. The first table uses `xtable()`, the second uses `stargazer()` [@hlavac18]. A third option is to use `texreg()`.

```{r}
#| label: linearxtable
#| echo: false
#| message: false
#| results: 'asis'

# We can print regression tables with xtable or stargazer:
regr_table <- xtable::xtable(lm_out,
                             digits = 2,
                             caption = "Our Informative Caption")

print(regr_table, comment = FALSE)
```

```{r}
#| label: linearstargazer
#| echo: false
#| message: false
#| results: 'asis'

# We can print regression tables with xtable or stargazer:
stargazer::stargazer(lm_out, 
                     title = "Our Informative Title",
                     dep.var.caption = "Outcome",
                     digits = 2,
                     header = FALSE)
```

```{r}
#| label: lineartexreg
#| echo: false
#| eval: false
#| message: false
#| results: 'asis'

# We can print regression tables with xtable or stargazer:
texreg::texreg(lm_out, 
                     caption = "Our Informative Title",
                     label = "lmout-texreg",
                     digits = 2)
```

Using the `cars` data, we find that each unit of speed is associated with `r round(cars_speed_coef, 1)` more units of distance. We draw out what this really means, and what it implies. For example, if a typical difference among our observations is 7 units of speed, then our model estimates that a typical difference in distance among our observations is $7 \times `r round(cars_speed_coef, 1)` = `r 7 * round(cars_speed_coef, 1)`$ units of distance. We describe the substantive relevance of this number.

We do not report estimates like `p = 3.242e-15`, since these are computational zeros. Instead, we write $p < 0.001$ or $p \approx 0$, as appropriate.

We do not report quantities to unhelpful degrees of precision. Although there were 112,030,874 votes cast from voting-eligible population of 242,690,810 in the U.S. in 2022, it is not helpful to report turnout as `r (112030874 / 242690810) * 100`%; writing `r round((112030874 / 242690810) * 100, 1)`% suffices.

## Comparing Distances between High- and Low-Speed Cars

```{r}
#| label: ttest
#| echo: false

# Create a binary variable for "high-speed":
cars <- cars |> mutate(hs = ifelse(speed > mean(speed), 1, 0))

# Conduct t-test:
t_out <- t.test(dist ~ hs, cars)

t_lower_ci <- t_out$conf.int[1] |> round(2)
t_upper_ci <- t_out$conf.int[2] |> round(2)
```

To report the results of a $t$-test, we do so in text, and perhaps in a well-formatted table as well, such as @tbl-ttesttable. Here, as above, we report the important details in text. For example, when we define "high-speed" cars as those traveling above the mean speed, the difference between the high-speed and low-speed group means is `r t_out$estimate[2] - t_out$estimate[1]`, with a 95% confidence interval that covers $(`r -t_upper_ci`, `r -t_lower_ci`)$.

```{r}
#| label: tbl-ttesttable
#| echo: false
#| warning: false
#| tbl-cap: Distance by Speed Group

parameters::model_parameters(t_out) |> 
  parameters::print_md(
    footer = "")
```

If I have tests of two outcomes from the same data, I can bind them together, as in @tbl-ttesttable2:

```{r}
#| label: tbl-ttesttable2
#| echo: false
#| warning: false
#| tbl-cap: Distance and Square-root Distance by Speed Group

cars <- cars |> mutate(dist_sqrt = (sqrt(dist)))
t_out_2 <- t.test(dist_sqrt ~ hs, data = cars)

tab <- bind_rows(
  as.data.frame(model_parameters(t_out)),
  as.data.frame(model_parameters(t_out_2))
)

tab |> 
  select(-CI, -Method, -Alternative) |>
  rename("Mean_1" = "Mean_Group1",
         "Mean_2" = "Mean_Group2",
         "df" = "df_error") |> 
  print_md(
    footer = "")
```

If we have trouble formatting using `{parameters}`, we can use `kable()` for one test, as in @tbl-ttesttable_kable, or two tests as in @tbl-ttesttable_kable2:

```{r}
#| label: tbl-ttesttable_kable
#| echo: false
#| warning: false
#| tbl-cap: Distance by Speed Group using `kable`

t_out_tidy <- t_out |> tidy() 

t_out_tidy |> select(-c(method, alternative)) |> 
  rename("Diff in Means" = estimate,
         "Group 0" = estimate1,
         "Group 1" = estimate2,
         "t-statistic" = statistic,
         "p-value" = p.value,
         "df" = parameter,
         "CI Lower" = conf.low,
         "CI Upper" = conf.high) |> kable(digits = 2)
```

```{r}
#| label: tbl-ttesttable_kable2
#| echo: false
#| warning: false
#| tbl-cap: Distance and Sqrt Distance by Speed Group using `kable`

t_out_tidy2 <- t_out_2 |> tidy() 

t_out_all <- bind_rows(t_out_tidy, t_out_tidy2) 

t_out_all |> select(-c(method, alternative)) |> 
  rename("Diff Means" = estimate,
         "Slow" = estimate1,
         "Fast" = estimate2,
         "t-stat" = statistic,
         "p-value" = p.value,
         "df" = parameter,
         "CI Lower" = conf.low,
         "CI Upper" = conf.high) |> 
  mutate(Outcome = c("Dist", "Dist Sqrt")) |>
  select(Outcome, everything()) |> 
  kable(digits = 2)
```

# Discussion

One limitation was our inability to involve third-party and non-partisan affiliations into our analysis. We recommend future work to be done that incorporates non-partisan affiliates, as they represented a large portion of the New York Voter File (26,108 voters of our 116,801 data set were non-partisan). In addition, other factors than the three we tested may be more responsible for party affiliation, such as education, party identification of parents, and race/ethnicity. The voter files alone did not contain a high quality measure, or one at all, for these potential predictors. We suggest the use of a survey to view correlation between these predicted determiners. A natural expansion of this project would be to do the same methodology for many states. Then, comparison between regions or different states could render intriguing findings. We were also limited by our access to the voter files. Were a more recent file be available, such as 2025, that would better encapsulate the voting dynamics of today's world than 2021. That being said, we expect limited changes for party identification as affiliation is rarely updated in official records. Additionally, it is likely that other predictors within our data set will glean interesting information related to partisanship. We chose predictors that are commonly described as strong influences, but it is possible some of the hundreds of other variables demonstrate correlations.

\clearpage

# References

Box-Steffensmeier, J. M., De Boef, S., & Lin, T.-M. (2004). The dynamics of the partisan gender gap. American Political Science Review, 98(3), 515–528. https://doi.org/10.1017/S0003055404001315

Knoke, D. & Hout, M. (1974). Social and demographic factors in American political party affiliations, 1952-72. American Sociological Review, 39(5), 700–713. https://doi.org/10.2307/2094315

Miller, W. E. (1991). Party identification, realignment, and party voting: Back to the basics. The American Political Science Review, 85(2), 557–568. https://doi.org/10.2307/1963175

Seo-young Kim, S. & Zilinsky, J. (2024). Division does not imply predictability: Demographics continue to reveal little about voting and partisanship. Political Behavior, 46(1), 67–87. https://doi.org/10.1007/s11109-022-09816-z

Tomkins, S., Rothschild, D., Liu, A., & Thompson, A. (2025). Identity isn’t everything—How far do demographics take us towards self-identified party ID? (No. arXiv:2507.06193). arXiv. https://doi.org/10.48550/arXiv.2507.06193
